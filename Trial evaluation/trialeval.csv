Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q8,Q9,Q10
The chatbot was good at guessing my emotion.,"When interacting with the persona named Kai, I found that they displayed empathy in their responses throughout the conversation.","When interacting with the persona named Kai, I found the conversation to be engaging.","Which other personas did you interact with, apart from Kai? (Select all that apply)","When interacting with the other personas (any apart from Kai), I found that they displayed empathy in their responses throughout the conversation.","When interacting with the other personas (any apart from Kai), I found the conversation to be engaging.","Overall, the platform was useful.",Please describe the overall emotional impact of your experience:,Do you have any further suggestions for how the platform can be improved?,Please provide any additional comments you have.
Disagree,Agree,Agree,"Robert,Arman",Agree,Agree,,"Well it was ok. There were more interactions this time but again limiting the feelings to just 4 or 5 categories doesn't seem helpful. Why ""being tired"" is considered as ""sad"" emotion. No need to push people to sadness. Instead the chatbot can use ""tired"" in their response and say ""I understand you had a hard day. I can help you by suggesting you doing one of these exercises, you will gain lots of positive energy for your rest of day."" Or if it's night time: ""I understand you had a hard day. I can help you by suggesting you doing one of these exercises, you will have a good night sleep.""
Isn't it better this way? 
By the way, are you checking the local time of the user in order to see if it's day time or night? For the above example, it seems it's better to be checked :)","I'm not sure if you have tried different devices to try and see how this chatbot page works or not. I had difficulty choosing the bot's responses and suggestions, scrolling down the page, reading the chat and the instructions on both iPhone and iPad using Safari. I tried Chrome on my iPhone which was slightly better as I could see the chatbot messages under the text box but again I couldn't scroll down the instructions part to see the protocols descriptions. I could only the see first page of it which ends with this sentence: ""Please scroll down ..."".
Furthermore the last time I tried the chatbot, I was trying to scroll up to see what were the previous protocol suggestions then the whole chat got restarted! So I was like well, I think I'm done trying to work with this chatbot.","Sorry that my comments seems discouraging. I totally understand how much effort you and the previous team have put to make this work better and I really appreciate your hard work. Please don't get me wrong. I'm sure by creating and improving this chatbot, you all are going to make a huge difference in lots of people's lives. 
Thanks for the hard work! :)"
Strongly agree,Neither agree nor disagree,Neither agree nor disagree,"Arman,Olivia",Strongly agree,Strongly agree,,"How come I hadnât worked for sometimes, but after I practiced the protocol, I easily could change my mood to a better level and I think thatâs because of the profound impression of the protocols the time we worked on. Also this new platform makes this good impression double as you are interacting with someone to do the process and itâs close to the real conversation.",,
Neither agree nor disagree,Agree,Agree,"Gabrielle,Arman",Agree,Agree,,"Again, as last time, I think this question needs to be rephrased and made more specific? (what do you mean by 'emotional impact'? Are you asking about the experience of using the chatbot or the experience of doing the protocols, or a mixture? ...)

Trying to decode the question based on my own interpretation, I would like to say the following:
* The chatbot was considerably more organic and empathetic in conversation and did make me feel heard and supported to a reasonable extent.
* Regardless of the chatbot, the experiential cycle of reflecting on my current emotional state, practicing a SAT protocol, and re-evaluating my state of mind had a positive impact on my focus and well being.","* As I mentioned, the language and flow of questions and responses was really empathetic. You are definitely on the right track on this. There are a couple of details, I would like to comment on below.

* The acknowledgement of our feelings was very effectively done, but I feel in conversations with multiple follow-up questions (typically when discussing negative emotions), it was a little overdone, which made it less organic than a similar conversation with a real person. In real life, when we acknowledge someone's feeling, we wouldn't typically repeat it verbally at the beginning of every other sentence, but would use more subtle ways to expand on the safe space created by the original acknowledgement (which could involve, more listening and less interruption - even if the interruption has an empathetic language). Of course, a great part of this is communicated non-verbally, which is not possible with a text chat bot, but I think there is still a lot that can be done to show more subtle manifestations of compassion even in text.

* One thing that I found slightly counter-productive was a specific way of ending the discussion on negative feelings. After a protocol was suggested and practiced, we would be asked if it helped and several times, I noticed that this question was immediately followed by something like ""I hope this helped"" or ""I hope you feel better"". In real-life empathy, this is not a good practice, as we're practically imposing a bias towards ""feeling better"". If we try to help someone in distress, and give them a chance to report back, the correct follow-up would be to ask an open question (how are you feeling now? how did it go?) followed by empathetic listening (in the case of the chatbot, perhaps it would be best to use the same AI to again interpret the response and follow up based on that).

","* Overall, this was a huge step in the right direction. I look forward to seeing the later versions as well. A few more comments and suggestions:

- The interface has a lot of room for improvement. The current version is not compatible with all devices. There are also several details that can be improved, which is beyond the scope of this feedback. I suggest you collect user feedback specifically on this aspect later in the research.

- I mentioned this in my feedback to the previous version (and there was a good attempt at improvement in this version, but my feedback still stands): Asking the participant to ""go, do the protocol, and come back"" somewhat disrupts the organic flow of the mentor/mentee conversation. Ideally, I would like to be guided by the chatbot persona in doing the protocol. Aspects of this was incorporated in the questioning (which I really appreciated), but I think there is still room for making it more streamlined.

- One feature of the last version, which for some reason was removed in this version, was the option to choose a different protocol than those recommended by the chatbot. I think this feature should not only be kept, but also improved to help the AI learn about why respondents are choosing those protocols and how the knowledge can be used to have better recommendations for them in future sessions.

- The addition of personas was great. I think more work is worth doing in making the persona relatable and ""real"" (for the first step, the chosen persona's avatar can be shown throughout the conversation. Right now, we'd choose a persona, but still see the face of everyone else along with our chosen identity.)

"
Agree,Agree,Agree,Robert,Agree,Agree,,It was overall very emotional experience. I could connect with Kai and Robert and Gabriella. ,"I think it was great, maybe some more empathetic phrases can help individuals in trouble,",
Agree,Strongly agree,Agree,"Robert,Olivia",Strongly agree,Agree,Strongly agree,The suggestions was appropriate and they helped me to improve my emotions.,,
Neither agree nor disagree,Agree,Agree,"Gabrielle,Arman",Neither agree nor disagree,Neither agree nor disagree,Agree,"The experience is quite powerful, but due to the SAT protocols. The bot helps, but I feel it is quite limited, the responses are often repeating.","Emotion recognition can be significantly improved with a corpus of synonyms. Responses could be more varied and flavorful. Often silly, funny even ridiculous responses can help. ",
Agree,Agree,Disagree,"Arman,Olivia",Neither agree nor disagree,Disagree,Neither agree nor disagree,,"The persona must ask deeper more details questions before suggesting protocols. Regardless of how much of the users' answers are actually used, the impression that someone is listening to me at the other end of the line, is very important I think.

The responses of the persona will be better received if they are in audio/video format, either through animation or ideally AI assisted recorded video.","The responses feel quite general. This in turn might make the user sceptical towards the effectiveness of the suggested protocols, even before trying them."
Disagree,Neither agree nor disagree,Neither agree nor disagree,Robert,Neither agree nor disagree,Neither agree nor disagree,Agree,I like the fact that the bot reminds me of the protocols ,"I think it would be a great idea if the bot itself gives a short reminder of the protocol item that it suggest. 

Also I think the bot tries to show up too much empathy in an artificial way.

Also, I think the bot os unable to understand complicated emotions. It simplifies the emotions a little too much.",I think it is better to focus on improving the bot as a tool to teach us the protocol itself at a deeper level. 
Agree,Agree,Neither agree nor disagree,Arman,Agree,Neither agree nor disagree,Agree,I enjoyed some protocols more than others. Exercise 13 and 20 were personal favourites as I felt as though they really boosted my mood.,"Potentially introduce more of a conversation rather than just clicking buttons to answer questions, but of course I understand this might be hard to implement.","The AI understood the main buzz words of my emotions. It did get confused once when I said ""I was feeling so so"" and it interpreted it as I was feeling happy, but in general it understood my emotions."
Agree,Agree,Agree,Robert,Agree,Agree,Agree,"With the conversation, I can gradually adjusted my emotions and let myself feel better.","After choosing the persona, maybe it's better to display that avatar at someplace to let users know who they are talking to.",The response from the chat bot maybe should be displayed one by one to make it like a real person i?
Strongly agree,Agree,Neither agree nor disagree,"Arman,Olivia",Strongly agree,Neither agree nor disagree,Agree,None,"One of the versions of questions asking for more information gave me the impression that I would have to type more information instead of selecting, so I chose not to provide this information (led to worse suggestions, the protocols I received did not appear to be relevant). Not sure if it would be better to just ask the questions instead of asking for user's approval on this - I noticed that the chatbot asks the user a lot more than in the previous version, which is good so the chatbot has permission to ask these questions but also leads to potentially worse suggestions.

I noticed 4 protocols were provided as suggestions each time as opposed to fewer suggestions in previous versions depending on the case, though some appear to have been randomly added and did not appear to be appropriate.

Instead of asking the user each time for their name, allow them to enter this in a separate page (or save this the first time the user asks for it). For this trial, this could have been manually filled in to avoid asking for it each time. However, integrating this with sentences to personalise the conversation was effective.

It would be nice if it was easier to switch between personas without needing to refresh e.g. by adding a button that allows you to select from the options, which then restarts the conversation.
","When I said I wasn't feeling well/great, these implicit emotions were not detected (suggested happy), but when I said I was not OK this was correctly detected as sad. Explicitly saying I was sad/happy gave the correct result.

Good use of dialogue, particularly for users with negative emotions.

When speaking with Kai, giving a negative emotion and saying I feel better, the follow-up suggestions did not seem to be consistent with the suggestions before (perhaps some were randomly shuffled?).

Good use of statements as questions to mix the dialogue up a bit - more varied dialogue.

For Arman, the following dialogue was vague: ""Is there anything going on in your personal life that is causing you to feel this way?"" - the wording is implicitly linked to friends/family but this could mean anything. When I said yes to this question, Protocol 1 was one of the suggestions - seemed inappropriate.

For Olivia: 
""I'm in tune with your emotion and we will understand how to overcome it."" - seems a little awkward to say, less realistic.
""Have you felt or shared any of these feelings with anyone in your life:"" <- perhaps could include some more details about how this would link to the feeling the person has.

Protocol 5 was one of the suggestions when I again selected yes to the personal life question - did not seem appropriate.

Overall, some of the prompts were inappropriate but the dialogue was largely empathetic and at times the different personas were engaging. It's great to see how this has developed over time.
"
Agree,Agree,Agree,"Robert,Gabrielle",Agree,Agree,Agree,,"1) I'm not sure what is the purpose of the panel (Protocol viewer) on the right-hand side? It was empty all the time and was taking up a half of the screen. Is that intentional?

2) Do I have to feel either better or worse after the session? One could feel the same, but that answer was not presented.

",
Neither agree nor disagree,Agree,Agree,"Arman,Olivia",Agree,Agree,Agree,I feel content after the protocols.,"It would be more engaging if the actual personas take you through the protocols themselves, step by step. This could make the chat more interactive. Just a thought.",
Neither agree nor disagree,Agree,Agree,Olivia,Neither agree nor disagree,Agree,Agree,"only some impact. Definitely limited, but detectable.","UI suggestions: Once you pick a persona, that persona's avatar should be the only one shown (preferably to the left of the text, just like iPhone). Right now, you still see all the other faces below and that's not very immersive to the one persona.

Second, the text parts of the SAT protocol should be just integrated into the chatbot interface itself, maybe even with images. The bot asking you to read something somewhere else (even if it's in the panel right next to you) is not as engaging.","I think you are relying too much on self motivation to follow through on all the protocols. For someone depressed for example, not sure there's motivation to (go do X and Y, and come back here and tell me if it worked). If the bot appears like it doesn't know the details of what it's asking you to do, it's not very reassuring."
Agree,Strongly agree,Strongly agree,"Robert,Gabrielle",Agree,Agree,Strongly agree,It is very useful and great,"I think if the bot can use some emotional pictures for guessing emotions, it would be more comfortable",Great welldone
Strongly agree,Agree,Agree,"Robert,Olivia",Agree,Strongly agree,Agree,It was good,It appears as if the responses are hardcoded. I suggest its answers should be dynamic. I asked a question like 'how are you?' and the answer was standard reply.  ,
